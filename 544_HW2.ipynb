{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports\n"
      ],
      "metadata": {
        "id": "Xnid_hYDFwRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "import math\n",
        "import sys"
      ],
      "metadata": {
        "id": "oSdKhzI7Fw76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1: Vocabulary Creation "
      ],
      "metadata": {
        "id": "hJxeP8MuFtPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Train Data\n"
      ],
      "metadata": {
        "id": "-PeIbEPfGhoH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NofnN4hnFot_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "ed024c34-a55e-4791-9296-6e23239d72a8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-235dc21bdc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/assignments/544/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/assignments/544/train'"
          ]
        }
      ],
      "source": [
        "dir = '/content/drive/MyDrive/544/'\n",
        "df = pd.read_csv(dir+'train',sep='\\t',header=None,skip_blank_lines=True)\n",
        "df_dev = pd.read_csv(dir+'dev',sep='\\t',header=None,skip_blank_lines=True)\n",
        "df_test = pd.read_csv(dir+'test',sep='\\t',header=None,skip_blank_lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LZ23tNg5ihS",
        "outputId": "04a4033e-6fc0-4470-9651-9d3c0533165d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131768, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvURBdA6RbZc",
        "outputId": "2bca02a2-fad9-49c8-b734-6c004ace1387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing the values which occure less than threshold with special token '< unk >'"
      ],
      "metadata": {
        "id": "3094-_clJEFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thrsh = 3\n",
        "\n",
        "df_voc = pd.DataFrame(df[1].value_counts()).reset_index()\n",
        "\n",
        "df_voc['index'] = np.where(df_voc[1]<thrsh,'<unk>',df_voc['index'])"
      ],
      "metadata": {
        "id": "zQYMEAuA_VWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_voc = df_voc.groupby(df_voc['index']).sum()"
      ],
      "metadata": {
        "id": "GtjeeQ-eFCNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting with occurances"
      ],
      "metadata": {
        "id": "bYJVyGNHI_Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_voc = df_voc.sort_values(by=1,ascending=False).reset_index()"
      ],
      "metadata": {
        "id": "iejcQd3RAn8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to txt file"
      ],
      "metadata": {
        "id": "HzUf4A9vI8xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = df_voc['index']"
      ],
      "metadata": {
        "id": "vi6nxH4B-Cot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_voc.to_csv('vocab.txt',sep='\\t',header = False,index=False)"
      ],
      "metadata": {
        "id": "2y16w8zrD23J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing values with < unk > in the train data"
      ],
      "metadata": {
        "id": "ncbIRLnoIORn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc = pd.DataFrame(df[1].value_counts()).reset_index().rename(columns={'index':1,1:3})"
      ],
      "metadata": {
        "id": "Ucc8LuyEIN5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(df,voc,on=1,how='left')"
      ],
      "metadata": {
        "id": "eECWS4w6IfuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[1] = np.where(df[3]<3,'<unk>',df[1])"
      ],
      "metadata": {
        "id": "FIUpS-OKJWfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2: Model Learning"
      ],
      "metadata": {
        "id": "z6JUCswOJa6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Transition Matrix"
      ],
      "metadata": {
        "id": "18Vs5lRYCv4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_set = list(set(df[2]))\n",
        "transition_dict = dict()\n",
        "\n",
        "for i in pos_set:\n",
        "  transition_dict['init',i]=0\n",
        "\n",
        "for i in pos_set:\n",
        "  for j in pos_set:\n",
        "    transition_dict[i,j]=0\n",
        "\n",
        "for i in df.values:\n",
        "  if i[0]==1:\n",
        "    transition_dict['init',i[2]]+=1\n",
        "\n",
        "for i in range(len(df[2])-1):\n",
        "  transition_dict[df[2][i],df[2][i+1]]+=1"
      ],
      "metadata": {
        "id": "1qc_T1nyROD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occur = df[2].value_counts()\n",
        "occur['init'] = df[0].value_counts()[1]\n",
        "for i,j in transition_dict.items():\n",
        "  transition_dict[i] = j/occur[i[0]]"
      ],
      "metadata": {
        "id": "R9-bXCIK7jy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Emission Matrix"
      ],
      "metadata": {
        "id": "n8kj8KqqC19d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_set = list(set(df[1]))\n",
        "emission_dict = dict()\n",
        "for i in pos_set:\n",
        "  \n",
        "  for j in word_set:\n",
        "    emission_dict[i,j]=0\n",
        "    \n",
        "for i in df.values:\n",
        "  emission_dict[(i[2],i[1])]+=1"
      ],
      "metadata": {
        "id": "jIRyQYCBCUOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(set([k[0] for k in emission_dict.keys()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdRXqyFVicmd",
        "outputId": "a7efaec0-9930-4aae-9d78-3f7608f802e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "occur = df[2].value_counts()\n",
        "for i,j in emission_dict.items():\n",
        "  emission_dict[i] = j/occur[i[0]]"
      ],
      "metadata": {
        "id": "4k7r2wGbE5Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hmm = dict()\n",
        "hmm['transition'] = dict(map(lambda x: (str(x[0]),x[1]),transition_dict.items()))\n",
        "hmm['emission'] = dict(map(lambda x: (str(x[0]),x[1]),emission_dict.items()))"
      ],
      "metadata": {
        "id": "mCQzwx15Gkmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hmm.json','w') as f:\n",
        "  json.dump(hmm,f)"
      ],
      "metadata": {
        "id": "CIOxc4KoP61A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####To matrix"
      ],
      "metadata": {
        "id": "2rsWya_Kl-Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = list(transition_dict.keys())\n",
        "rows_labels = ['init']\n",
        "cols_labels = pos_set\n",
        "rows_labels.extend(cols_labels)\n",
        "rows, cols = [rows_labels.index(k[0]) for k in keys], [cols_labels.index(k[1]) for k in keys]"
      ],
      "metadata": {
        "id": "YAcwZNOgQJd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(rows),max(cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "932RA0Kglmu1",
        "outputId": "3b1bc954-01ae-4b71-e4fe-b03f52b07823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transition_matrix = np.zeros((max(rows)+1, max(cols)+1))\n",
        "for i, j in zip(rows, cols):\n",
        "    transition_matrix[i, j] = transition_dict[(rows_labels[i],cols_labels[j])]"
      ],
      "metadata": {
        "id": "HSWddUQCgKrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = list(emission_dict.keys())\n",
        "x_labels = cols_labels\n",
        "y_labels = list(df_voc['index'])"
      ],
      "metadata": {
        "id": "PXjQn5sOb4lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows, cols = [x_labels.index(k[0]) for k in keys], [y_labels.index(k[1]) for k in keys]"
      ],
      "metadata": {
        "id": "RbWgNhJ6gD8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emission_matrix = np.zeros((max(rows)+1, max(cols)+1))"
      ],
      "metadata": {
        "id": "B0EkDFlccE7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(rows, cols):\n",
        "    emission_matrix[i, j] = emission_dict[(x_labels[i],y_labels[j])]"
      ],
      "metadata": {
        "id": "9UaYDY4zhIki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Greedy Algorithm\n"
      ],
      "metadata": {
        "id": "tIG2lWCtKY-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(states,data,transition,emission,vocab):\n",
        "  tag_seq = []\n",
        "  prev_state = None\n",
        "  for i in data.values:\n",
        "    word = i[1]\n",
        "    if word not in vocab:\n",
        "      word = '<unk>'\n",
        "    if i[0]==1:\n",
        "      prev_state = 'init'\n",
        "    prev_state = states[np.argmax(list(map(lambda x: transition_dict[prev_state,x]*emission_dict[x,word],states)))]\n",
        "    tag_seq.append(prev_state)\n",
        "  return tag_seq"
      ],
      "metadata": {
        "id": "lCkWvYHfKYOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = pos_set\n",
        "data = df_dev[[0,1]]\n",
        "tag_seq = greedy(states,data,transition_dict,emission_dict,list(vocab))"
      ],
      "metadata": {
        "id": "j-w5CpkjA-aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "for i,j in zip(df_dev[2],tag_seq):\n",
        "  if i == j:\n",
        "    correct+=1\n",
        "print(f'Accuracy: {round(correct*100/len(tag_seq),2)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v10zdJHML6Bt",
        "outputId": "73ec5294-3986-4b8c-db97-31beef36acdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df_test[[0,1]]\n",
        "pred_seq_test = greedy(states,data,transition_dict,emission_dict,vocab)"
      ],
      "metadata": {
        "id": "-2_jbOF_K8vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('greedy.out','w') as f:\n",
        "  for i in zip(df_test.values,pred_seq_test):\n",
        "    f.write(f'{i[0][0]}\\t{i[0][1]}\\t{i[1]}\\n')"
      ],
      "metadata": {
        "id": "PxbH6Lb0Akpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Viterbi Algorithm "
      ],
      "metadata": {
        "id": "3mcP270CKhva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_decoding(emission_matrix, transition_matrix, observation_sequence,pos_set,vocab):\n",
        "    num_states = len(pos_set)\n",
        "    num_observations = len(observation_sequence)\n",
        "    viterbi = np.zeros((num_states, num_observations))\n",
        "    backpointer = np.zeros((num_states, num_observations), dtype=int)\n",
        "    o_0 = observation_sequence[0]\n",
        "    if o_0 not in vocab:\n",
        "        o_0 = '<unk>'\n",
        "    for state in range(num_states):\n",
        "        viterbi[state, 0] = transition_matrix['init', pos_set[state]] * emission_matrix[pos_set[state], o_0]\n",
        "        backpointer[state, 0] = 0\n",
        "\n",
        "    for t in range(1, num_observations):\n",
        "        obs = observation_sequence[t]\n",
        "        if observation_sequence[t] not in vocab:\n",
        "            obs = '<unk>'\n",
        "        \n",
        "        for state in range(num_states):\n",
        "            max_prob = -99999999\n",
        "            max_state = -99999999\n",
        "            for prev_state in range(num_states):\n",
        "                prob = viterbi[prev_state, t-1] + math.log(sys.float_info.epsilon+transition_matrix[pos_set[prev_state], pos_set[state]]) + math.log(sys.float_info.epsilon+emission_matrix[pos_set[state], obs])\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    max_state = prev_state\n",
        "            viterbi[state, t] = max_prob\n",
        "            backpointer[state, t] = max_state\n",
        "    \n",
        "    best_path = [0] * num_observations\n",
        "    max_prob = -1\n",
        "    final_state = -1\n",
        "    for state in range(num_states):\n",
        "        if viterbi[state, num_observations-1] > max_prob:\n",
        "            max_prob = viterbi[state, num_observations-1]\n",
        "            final_state = state\n",
        "    \n",
        "    best_path[num_observations-1] = final_state\n",
        "    for t in range(num_observations-2, -1, -1):\n",
        "        final_state = backpointer[final_state, t]\n",
        "        best_path[t] = final_state\n",
        "    \n",
        "    return best_path\n"
      ],
      "metadata": {
        "id": "_958AUJc8waq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = viterbi_decoding(emission_dict,transition_dict, df_dev[1],pos_set,list(vocab))\n",
        "pred_tags=[]\n",
        "for i in path:\n",
        "  pred_tags.append(pos_set[i])"
      ],
      "metadata": {
        "id": "WaNsSnLDrFhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "for i,j in zip(df_dev[2],pred_tags[1:]):\n",
        "  if i == j:\n",
        "    correct+=1\n",
        "print(f'Accuracy: {correct*100/len(pred_tags)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIB6yVzfmVRK",
        "outputId": "ea2e7ac7-efb8-4e57-c8c4-56d84194dd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.40076498087548%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = viterbi_decoding(emission_dict,transition_dict, df_test[1],pos_set,list(vocab))\n",
        "pred_tags=[]\n",
        "for i in path:\n",
        "  pred_tags.append(pos_set[i])"
      ],
      "metadata": {
        "id": "sOULY9-VQTyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('viterbi.out','w') as f:\n",
        "  for i in zip(df_test.values,pred_tags):\n",
        "    f.write(f'{i[0][0]}\\t{i[0][1]}\\t{i[1]}\\n')"
      ],
      "metadata": {
        "id": "tKfDIEteQNfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2nRseHeQXzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}