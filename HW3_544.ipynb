{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi78UyTRWGPG"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQFPUvpiWMHl"
      },
      "source": [
        "### Installing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am3I6IaDWPi3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install contractions\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install nltk\n",
        "!pip install re\n",
        "!pip install bs4\n",
        "!pip install string\n",
        "!pip install contractions\n",
        "!pip install gensim\n",
        "!pip install gensim\n",
        "!pip install -U scikit-learn\n",
        "!pip install pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tub_nOMiWKo9"
      },
      "source": [
        "## Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKrzVkdWJajb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "import contractions\n",
        "import gensim\n",
        "import gensim.models\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import precision_recall_fscore_support as scores\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU1hXOwldKxg",
        "outputId": "7deee70a-1e3e-4e56-c117-40bd182e93e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.3.0\n"
          ]
        }
      ],
      "source": [
        "print(gensim.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qevW8RP-Twyd"
      },
      "source": [
        "## Missing values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "806Nq2ncJsDB"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(\"amazon_reviews_us_Beauty_v1_00.tsv\", sep = '\\t', on_bad_lines= 'skip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IenTG-MrLmXl",
        "outputId": "4dbe1f44-5532-4411-c949-58ffe39f216f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df[[\"review_body\", \"star_rating\"]]\n",
        "data.dropna(subset = [\"star_rating\"], inplace= True)\n",
        "data[\"star_rating\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lX6LGAcNrxK",
        "outputId": "c1cd9a18-8509-410f-eaa1-8cb58c8cc185"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dropna(subset = [\"review_body\"], inplace= True)\n",
        "data[\"review_body\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bvmiBMvP4TP",
        "outputId": "bc615003-0ae7-49d9-db3a-ea127233c652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          None\n",
              "1          None\n",
              "2          None\n",
              "3          None\n",
              "4          None\n",
              "           ... \n",
              "5094302    None\n",
              "5094303    None\n",
              "5094304    None\n",
              "5094305    None\n",
              "5094306    None\n",
              "Name: star_rating, Length: 5093907, dtype: object"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def splitting(text):\n",
        "  text = str(text)\n",
        "  text = text[0]\n",
        "  return text\n",
        "\n",
        "def change_type(text):\n",
        "  text = int(text)\n",
        "  return text\n",
        "\n",
        "def typ(text):\n",
        "  if type(text)!=int:\n",
        "    print(type(text), text)\n",
        "\n",
        "data[\"star_rating\"] =data[\"star_rating\"].apply(lambda x : splitting(x))\n",
        "data['star_rating'] = data[\"star_rating\"].apply(lambda x: change_type(x))\n",
        "data[\"star_rating\"].apply(lambda x : typ(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBY8t6VAQaFI"
      },
      "source": [
        " ## We form three classes and select 20000 reviews randomly from each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWNj6KNvQNfA"
      },
      "outputs": [],
      "source": [
        "data_1 = data[data['star_rating']==1]\n",
        "data_1 = data_1.append(data[data['star_rating']==2])\n",
        "data_1[\"label\"] = 1\n",
        "data_1 = data_1.sample(n=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvVPtpMXQq6R"
      },
      "outputs": [],
      "source": [
        "data_2 = data[data['star_rating']==3]\n",
        "data_2 = data_2.append(data[data['star_rating']==4])\n",
        "data_2[\"label\"] = 2\n",
        "data_2 = data_2.sample(n=20000)\n",
        "data_1 = data_1.append(data_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDouaUfQQroi"
      },
      "outputs": [],
      "source": [
        "data_3 = data[data['star_rating']==5]\n",
        "data_3[\"label\"] = 3\n",
        "data_3 = data_3.sample(n=20000)\n",
        "data_1 = data_1.append(data_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cvIRh2AgQtDD",
        "outputId": "af9b26ef-a524-45ba-c5bf-6f2f41e7dca1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3749382</th>\n",
              "      <td>I use Elizabeth Arden &amp;#34;Overnight success&amp;#...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520778</th>\n",
              "      <td>Was disappointed in the quality.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510908</th>\n",
              "      <td>These brush heads are suppose to be for sensit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2237476</th>\n",
              "      <td>I have several bracelets like this and this on...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842395</th>\n",
              "      <td>Very good nail hardener. You must use it every...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               review_body  label\n",
              "3749382  I use Elizabeth Arden &#34;Overnight success&#...      1\n",
              "1520778                   Was disappointed in the quality.      1\n",
              "510908   These brush heads are suppose to be for sensit...      1\n",
              "2237476  I have several bracelets like this and this on...      1\n",
              "1842395  Very good nail hardener. You must use it every...      1"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = data_1[['review_body','label']]\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4q2_WfOVqSt"
      },
      "source": [
        "## Data Cleaning and Preprocessing.\n",
        "  1. Removing Unnecessary data from reviews\n",
        "  2. Contractions etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-JBTZXZV6JV"
      },
      "source": [
        "### Contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6fI3YpP9Voc8",
        "outputId": "05e44c46-b17a-4bad-ef71-a6e8f4904ca2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>label</th>\n",
              "      <th>contracted_reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3749382</th>\n",
              "      <td>I use Elizabeth Arden &amp;#34;Overnight success&amp;#...</td>\n",
              "      <td>1</td>\n",
              "      <td>I use Elizabeth Arden &amp;#34;Overnight success&amp;#...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520778</th>\n",
              "      <td>Was disappointed in the quality.</td>\n",
              "      <td>1</td>\n",
              "      <td>Was disappointed in the quality.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510908</th>\n",
              "      <td>These brush heads are suppose to be for sensit...</td>\n",
              "      <td>1</td>\n",
              "      <td>These brush heads are suppose to be for sensit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2237476</th>\n",
              "      <td>I have several bracelets like this and this on...</td>\n",
              "      <td>1</td>\n",
              "      <td>I have several bracelets like this and this on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842395</th>\n",
              "      <td>Very good nail hardener. You must use it every...</td>\n",
              "      <td>1</td>\n",
              "      <td>Very good nail hardener. You must use it every...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               review_body  label  \\\n",
              "3749382  I use Elizabeth Arden &#34;Overnight success&#...      1   \n",
              "1520778                   Was disappointed in the quality.      1   \n",
              "510908   These brush heads are suppose to be for sensit...      1   \n",
              "2237476  I have several bracelets like this and this on...      1   \n",
              "1842395  Very good nail hardener. You must use it every...      1   \n",
              "\n",
              "                                        contracted_reviews  \n",
              "3749382  I use Elizabeth Arden &#34;Overnight success&#...  \n",
              "1520778                   Was disappointed in the quality.  \n",
              "510908   These brush heads are suppose to be for sensit...  \n",
              "2237476  I have several bracelets like this and this on...  \n",
              "1842395  Very good nail hardener. You must use it every...  "
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[\"contracted_reviews\"] = df_train[\"review_body\"].apply(lambda x : contractions.fix(x) )\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgJOjZl-VoV8",
        "outputId": "9c9a94f5-80ef-4d10-a2f0-f1545cddaff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before and After Contraction: 266.22585 267.5654666666667\n"
          ]
        }
      ],
      "source": [
        "print(\"Before and After Contraction:\", (df_train[\"review_body\"].str.len()).mean(),(df_train[\"contracted_reviews\"].str.len()).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7WaGTsLfiY4"
      },
      "source": [
        "### Removing Punctuation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVKZTB2FfmJz"
      },
      "outputs": [],
      "source": [
        "df_p = pd.DataFrame()\n",
        "df_p[\"Punc\"] = df_train[\"contracted_reviews\"].apply(lambda x : \"\".join([char for char in x if char not in string.punctuation ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX4Lb7MvftHa",
        "outputId": "5866d171-952e-4344-de4c-6a2dbb20976d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before and After removing punc: 267.5654666666667 259.13755\n"
          ]
        }
      ],
      "source": [
        "print(\"Before and After removing punc:\", (df_train[\"contracted_reviews\"].str.len()).mean(),(df_p[\"Punc\"].str.len()).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LCEhFBLf3N6"
      },
      "source": [
        "### Keep Important Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl196TgCf6kz"
      },
      "outputs": [],
      "source": [
        "df_info = pd.DataFrame()\n",
        "df_info[\"Info\"] = df_train[\"contracted_reviews\"].apply(lambda x : re.split(\"\\W+\", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWKLVlnzgE9z",
        "outputId": "f8133e0d-54fa-4312-89e9-dd947edab3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before and After Keeping only important words: 267.5654666666667 52.437266666666666\n"
          ]
        }
      ],
      "source": [
        "print(\"Before and After Keeping only important words:\", (df_train[\"contracted_reviews\"].str.len()).mean(),(df_info[\"Info\"].str.len()).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhOpxIcknClM"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh2qc4FFyAnO"
      },
      "outputs": [],
      "source": [
        "stopword = stopwords.words(\"english\")\n",
        "stopword.append(stopwords.words('french'))\n",
        "ps = nltk.PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPJrAFQ8edL9"
      },
      "outputs": [],
      "source": [
        "df_stem = pd.DataFrame()\n",
        "df_stem[\"Stemmed\"] = df_train[\"contracted_reviews\"].apply(lambda x : ps.stem(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QMzS6Kee6l-",
        "outputId": "b7810090-aa0a-4555-cd89-ba41decab3d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before and After Stemming: 267.5654666666667 267.4111833333333\n"
          ]
        }
      ],
      "source": [
        "print(\"Before and After Stemming:\", (df_train[\"contracted_reviews\"].str.len()).mean(),(df_stem[\"Stemmed\"].str.len()).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK1zGaz8XorD"
      },
      "source": [
        "### Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exLdjFGlVoRl"
      },
      "outputs": [],
      "source": [
        "wn = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3TlXxy9fWQ_"
      },
      "outputs": [],
      "source": [
        "df_lem = pd.DataFrame()\n",
        "df_lem[\"lem\"] = df_train[\"contracted_reviews\"].apply(lambda x : wn.lemmatize(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCUkPImfWRA",
        "outputId": "598c8cdc-7c61-4223-f2c2-752804747019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before and After Lemmatizing: 267.5654666666667 267.56536666666665\n"
          ]
        }
      ],
      "source": [
        "print(\"Before and After Lemmatizing:\", (df_train[\"contracted_reviews\"].str.len()).mean(),(df_lem[\"lem\"].str.len()).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv2DkM-JhR0m"
      },
      "source": [
        "### Applying all using Clean Data Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UgJBchQVoME"
      },
      "outputs": [],
      "source": [
        "stopword = stopwords.words(\"english\")\n",
        "ps = nltk.PorterStemmer()\n",
        "wn = WordNetLemmatizer()\n",
        "def clean_data(text):\n",
        "  text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "  token = re.split(\"\\W+\", text)\n",
        "  words = [wn.lemmatize(word) for word in token if word not in stopword]\n",
        "  #words = [ps.stem(word) for word in words if word not in stopword]\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAiO0wBEhaM3"
      },
      "outputs": [],
      "source": [
        "df_train[\"reviews\"]= df_train[\"contracted_reviews\"].apply(lambda x : clean_data(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr8PUfGbhjKP"
      },
      "outputs": [],
      "source": [
        "df_train.drop([\"review_body\",'contracted_reviews'], axis =1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-M1CL5KftIr9",
        "outputId": "81704276-6759-49d3-fe1d-fb8f702b6976"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3749382</th>\n",
              "      <td>1</td>\n",
              "      <td>[I, use, Elizabeth, Arden, 34Overnight, succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520778</th>\n",
              "      <td>1</td>\n",
              "      <td>[Was, disappointed, quality]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510908</th>\n",
              "      <td>1</td>\n",
              "      <td>[These, brush, head, suppose, sensitive, skin,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2237476</th>\n",
              "      <td>1</td>\n",
              "      <td>[I, several, bracelet, like, one, worst, quality]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1842395</th>\n",
              "      <td>1</td>\n",
              "      <td>[Very, good, nail, hardener, You, must, use, e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         label                                            reviews\n",
              "3749382      1  [I, use, Elizabeth, Arden, 34Overnight, succes...\n",
              "1520778      1                       [Was, disappointed, quality]\n",
              "510908       1  [These, brush, head, suppose, sensitive, skin,...\n",
              "2237476      1  [I, several, bracelet, like, one, worst, quality]\n",
              "1842395      1  [Very, good, nail, hardener, You, must, use, e..."
            ]
          },
          "execution_count": 271,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfmDvycZ--h6"
      },
      "outputs": [],
      "source": [
        "#df_train.to_csv(\"/content/drive/MyDrive/544/hw3/review.csv\", )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNHm9PyP_Svh"
      },
      "outputs": [],
      "source": [
        "#data = pd.read_csv(\"/content/drive/MyDrive/544/hw3/review.csv\", sep ='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTXdqtFo1_Q3"
      },
      "outputs": [],
      "source": [
        "s= []\n",
        "for i in df_train[\"reviews\"]:\n",
        "  s.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g33wP608VjV9"
      },
      "source": [
        "## Task 2: Word Embedding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvKgtxkGQxri"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "wv = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dglPA9qmAKIT"
      },
      "outputs": [],
      "source": [
        "#pickle.dump(wv,open(\"/content/drive/MyDrive/544/hw3/\"+\"google_wv\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBjWFHNA7oM4"
      },
      "source": [
        "## Part a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khOrshUXRrxk",
        "outputId": "cb5388aa-5466-4230-f541-5b337b454879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'house'\t'home'\t0.56\n",
            "'husband'\t'wife'\t0.83\n",
            "'tea'\t'coffee'\t0.56\n",
            "'son'\t'child'\t0.52\n",
            "'man'\t'woman'\t0.77\n"
          ]
        }
      ],
      "source": [
        "pairs = [\n",
        "    ('house', 'home'),   # a house with a family is home\n",
        "    ('husband','wife'),   # spouse\n",
        "    ('tea', 'coffee'),  # common beverages\n",
        "    ('son', 'child'),\n",
        "    ('man','woman')    # ... and so on \n",
        "\n",
        "]\n",
        "for w1, w2 in pairs:\n",
        "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPv3rx_N7oM5"
      },
      "source": [
        "## Part b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUQYwgHB0Iy6"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(sentences=s, min_count=10,vector_size=300,window=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSLzMs8TkAcl",
        "outputId": "6d6999d1-22ec-46ed-9804-2afa6f4a6a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word #0/8292 is I\n",
            "word #1/8292 is product\n",
            "word #2/8292 is hair\n",
            "word #3/8292 is It\n",
            "word #4/8292 is like\n",
            "word #5/8292 is The\n",
            "word #6/8292 is use\n",
            "word #7/8292 is would\n",
            "word #8/8292 is one\n",
            "word #9/8292 is This\n"
          ]
        }
      ],
      "source": [
        "for index, word in enumerate(model.wv.index_to_key):\n",
        "    if index == 10:\n",
        "        break\n",
        "    print(f\"word #{index}/{len(model.wv.index_to_key)} is {word}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4bj3gGAwZjq",
        "outputId": "8e16e23d-ca2e-4e61-81a7-823a21d009f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'house'\t'home'\t0.58\n",
            "'husband'\t'wife'\t0.89\n",
            "'tea'\t'coffee'\t0.56\n",
            "'son'\t'child'\t0.49\n",
            "'man'\t'woman'\t0.59\n"
          ]
        }
      ],
      "source": [
        "pairs = [\n",
        "    ('house', 'home'),   # a house with a family is home\n",
        "    ('husband','wife'),   # spouse\n",
        "    ('tea', 'coffee'),  # common beverages\n",
        "    ('son', 'child'),\n",
        "    ('man','woman')    # ... and so on \n",
        "\n",
        "]\n",
        "for w1, w2 in pairs:\n",
        "    print('%r\\t%r\\t%.2f' % (w1, w2, model.wv.similarity(w1, w2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGJ3gwev7oM7"
      },
      "source": [
        "For some of the given examples used for checking similarities, my trained model works better than pretrained eg, (house, home) and (husband and wife). All other work better in the pretrained model. Therefore pretrained works better as it 3/5 has high simmilarities compare to my model.\n",
        "We can have better accuracy or simmilarity if we would have trained our dataset on pretrained model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WdDSiQ7hnG2"
      },
      "source": [
        "## Task 3: Simple Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3XE40DyfMzc"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgTX5EiJYBpo"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "indices = []\n",
        "for index, sentences in enumerate(df_train[\"reviews\"]):\n",
        "    \n",
        "    embeddings = []\n",
        "    for word in sentences:\n",
        "        try:\n",
        "            word_embedding = wv[word]\n",
        "            embeddings.append(word_embedding)\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if len(embeddings)>0:\n",
        "      review_embedding = np.mean(embeddings, axis=0)\n",
        "      X_train.append(np.array(review_embedding))\n",
        "    else:\n",
        "      indices.append(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-phrk533mfh",
        "outputId": "2040fed0-0c2b-4b38-8f90-f8c9889951a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 279,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train)+len(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mOpjoQEZbIM"
      },
      "outputs": [],
      "source": [
        "for i, label in enumerate(df_train[\"label\"]):\n",
        "  if i not in indices:\n",
        "    y_train.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mHXiYxBfXOe"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, Y_train, Y_test=train_test_split(X_train, y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Pzss9K7oM9"
      },
      "source": [
        "## Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k205wIc2GTm",
        "outputId": "d2891a43-d7c9-4df3-ed13-6724f1dcd28e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "Perceptron()"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train a single perceptron on the extracted average word embeddings\n",
        "perceptron_model = Perceptron()\n",
        "perceptron_model.fit(x_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRymNMRNfyrf",
        "outputId": "8f440e05-aecb-47d3-fce8-9199708bf6da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5037148342933467"
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score( Y_test,perceptron_model.predict(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kohHcj2I7oM9"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKXlqQ5J2Pxi",
        "outputId": "28c25092-dcd1-44d1-ee8f-d78109f7acc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train an SVM on the extracted average word embeddings\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdnhOpNygYb3",
        "outputId": "3129c0db-250b-4277-b9ee-8fe3c8a5c59c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6386175807663411"
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score( Y_test,svm_model.predict(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY3Gn1w_7oM-"
      },
      "source": [
        "Comparing the accuracies among Tf-Idf and word2vec:\n",
        "Accuracy : Perceptron in TFIDF has 60% and SVM had 66%. Whereas in WORD2Vec SVM has 63 and Perceptron has 50.\n",
        "\n",
        "\n",
        "We can conclude that for simple models TF-IDF performs better compare to word2vec.  This also states that dataset work well on keyword-based matching\n",
        " and as we are also using a small dataset. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aduXTX0_FoDg"
      },
      "source": [
        "## Task 4 : Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtWvd5RDjmj8"
      },
      "source": [
        "### 4.a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YawkWKU3dBK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlviPDO1h59G"
      },
      "outputs": [],
      "source": [
        "#Creating tensor data\n",
        "#training data\n",
        "xtrain_np=np.array(x_train)\n",
        "x=torch.from_numpy(xtrain_np)\n",
        "\n",
        "ytrain_np=np.array(Y_train)\n",
        "y=torch.from_numpy(ytrain_np)\n",
        "\n",
        "#testing data\n",
        "xtest_np=np.array(x_test)\n",
        "test_x=torch.from_numpy(xtest_np)\n",
        "\n",
        "ytest_np=np.array(Y_test)\n",
        "test_y=torch.from_numpy(ytest_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceTMQ7oZeUCd"
      },
      "outputs": [],
      "source": [
        "model=torch.nn.Sequential(\n",
        "    torch.nn.Linear(300,100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100,10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(10,10)    \n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.2\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev7TloMKene9",
        "outputId": "f582466d-f02c-4856-c080-3b8719a49e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " traning Accuracy for 0 - tensor(0.0047)\n",
            " traning Accuracy for 50 - tensor(0.3819)\n",
            " traning Accuracy for 100 - tensor(0.4160)\n",
            " traning Accuracy for 150 - tensor(0.4514)\n",
            " traning Accuracy for 200 - tensor(0.5196)\n",
            " traning Accuracy for 250 - tensor(0.5217)\n",
            " traning Accuracy for 300 - tensor(0.4997)\n",
            " traning Accuracy for 350 - tensor(0.4545)\n",
            " traning Accuracy for 400 - tensor(0.4762)\n",
            " traning Accuracy for 450 - tensor(0.4970)\n",
            " traning Accuracy for 500 - tensor(0.5117)\n",
            " traning Accuracy for 550 - tensor(0.5286)\n",
            " traning Accuracy for 600 - tensor(0.5435)\n",
            " traning Accuracy for 650 - tensor(0.5549)\n",
            " traning Accuracy for 700 - tensor(0.5651)\n",
            " traning Accuracy for 750 - tensor(0.5744)\n",
            " traning Accuracy for 800 - tensor(0.5828)\n",
            " traning Accuracy for 850 - tensor(0.5880)\n",
            " traning Accuracy for 900 - tensor(0.5929)\n",
            " traning Accuracy for 950 - tensor(0.5978)\n"
          ]
        }
      ],
      "source": [
        "model=model.float()\n",
        "for t in range(1000):\n",
        "    y_pred = model(x.float())\n",
        "    loss = criterion(y_pred, y)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    if(t%50==0):\n",
        "        pred=model(x.float())\n",
        "        _,predicted = torch.max(pred.data,1)\n",
        "        correct = (predicted == y).sum()\n",
        "        print(\" traning Accuracy for\",t,\"-\",correct/len(y))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1W309Nrerhh",
        "outputId": "9c235101-1a12-4653-9cbe-2c0849794d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for question 4a: tensor(0.6122)\n"
          ]
        }
      ],
      "source": [
        "pred=model(test_x.float())\n",
        "_,predicted = torch.max(pred.data,1)\n",
        "correct = (predicted == test_y).sum()\n",
        "print(\"Accuracy for question 4a:\",correct/len(test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9N3PRMfjoxm"
      },
      "source": [
        "### 4.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQP3dQfxe1qK"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "indices = []\n",
        "for index, sentences in enumerate(df_train[\"reviews\"]):\n",
        "    \n",
        "    embeddings = []\n",
        "    for i, word in enumerate(sentences):\n",
        "        if i<10:\n",
        "          try:\n",
        "              word_embedding = wv[word]\n",
        "              embeddings.append(word_embedding)\n",
        "          except KeyError:\n",
        "              continue\n",
        "        else:\n",
        "          break\n",
        "    if len(embeddings)>0:\n",
        "      review_embedding = np.mean(embeddings, axis=0)\n",
        "      X_train.append(np.array(review_embedding))\n",
        "    else:\n",
        "      indices.append(index)\n",
        "\n",
        "for i, label in enumerate(df_train[\"label\"]):\n",
        "  if i not in indices:\n",
        "    y_train.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2wJYk2OkBxN"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,Y_train, Y_test = train_test_split(X_train,y_train, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRU0tFpSkLgE"
      },
      "outputs": [],
      "source": [
        "#Creating tensor data\n",
        "#training data\n",
        "xtrain_np=np.array(x_train)\n",
        "x=torch.from_numpy(xtrain_np)\n",
        "\n",
        "ytrain_np=np.array(Y_train)\n",
        "y=torch.from_numpy(ytrain_np)\n",
        "\n",
        "#testing data\n",
        "xtest_np=np.array(x_test)\n",
        "test_x=torch.from_numpy(xtest_np)\n",
        "\n",
        "ytest_np=np.array(Y_test)\n",
        "test_y=torch.from_numpy(ytest_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIZplur9l2ld"
      },
      "outputs": [],
      "source": [
        "model=torch.nn.Sequential(\n",
        "    torch.nn.Linear(300,100),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(100,10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(10,10)    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yuhgtPgl6aa"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp8taXU7l9ud",
        "outputId": "a8c53117-cba4-44b8-982d-eac1ae2cc9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " train Accuracy for 0 - tensor(0.3342)\n",
            " train Accuracy for 10 - tensor(0.3342)\n",
            " train Accuracy for 20 - tensor(0.3342)\n",
            " train Accuracy for 30 - tensor(0.3338)\n",
            " train Accuracy for 40 - tensor(0.3361)\n",
            " train Accuracy for 50 - tensor(0.3313)\n",
            " train Accuracy for 60 - tensor(0.3396)\n",
            " train Accuracy for 70 - tensor(0.3343)\n",
            " train Accuracy for 80 - tensor(0.3343)\n",
            " train Accuracy for 90 - tensor(0.3343)\n",
            " train Accuracy for 100 - tensor(0.3343)\n",
            " train Accuracy for 110 - tensor(0.3236)\n",
            " train Accuracy for 120 - tensor(0.3156)\n",
            " train Accuracy for 130 - tensor(0.3155)\n",
            " train Accuracy for 140 - tensor(0.3160)\n"
          ]
        }
      ],
      "source": [
        "model=model.float()\n",
        "for t in range(150):\n",
        "    y_pred=model(x.float())\n",
        "    loss = criterion(y_pred, y)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    if(t%10==0):\n",
        "        pred=model(x.float())\n",
        "        _,predicted = torch.max(pred.data,1)\n",
        "        correct = (predicted == y).sum()\n",
        "        print(\" train Accuracy for\",t,\"-\",correct/len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbz6vy-NmBEk"
      },
      "outputs": [],
      "source": [
        "pred=model(test_x.float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfIfrsJ1mBhK",
        "outputId": "6e040042-7b2e-443e-e6e9-7fedb7a97a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy - 4b: tensor(0.3176)\n"
          ]
        }
      ],
      "source": [
        "_,predicted = torch.max(pred.data,1)\n",
        "correct = (predicted == test_y).sum()\n",
        "print(\"Test Accuracy - 4b:\",correct/len(test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQCQKkLv7oND"
      },
      "source": [
        "Comparing the accuracies:\n",
        "Initially using complete sentences in MLP was better (61) compare to perceptron but not compare to svm. \n",
        "Later when using only 10 words in sentences MLP performance has depleted and got accuracy of 31, way low compare to svm and perceptron.\n",
        "\n",
        "We can conclude that by reducing the no of words in sentence, the performance quality also reduces. May be the vital information might have lost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xoERu6lmed4"
      },
      "source": [
        "## Task 5 : RNN, GRU, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIj3cf2uHchR"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame()\n",
        "features=[]\n",
        "for lis in df_train['reviews']:\n",
        "    wordvecs=[]\n",
        "    vector=np.zeros(300,)\n",
        "    for j in range(len(lis)):\n",
        "        if(j>=20):\n",
        "            break\n",
        "        else:\n",
        "            if lis[j] in wv.key_to_index:\n",
        "                wordvecs.append(wv[lis[j]])\n",
        "    while len(wordvecs)<20:\n",
        "        wordvecs.append(np.zeros(300,))\n",
        "        \n",
        "    features.append(wordvecs)\n",
        "    \n",
        "X['input_3']=features\n",
        "Y = df_train['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiAE2iqvH5k_"
      },
      "outputs": [],
      "source": [
        "df = X.input_3.apply(pd.Series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmrAC0cB7oNE"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,Y_train, Y_test = train_test_split(df,Y, test_size=0.2, random_state=30)\n",
        "\n",
        "x=X_train\n",
        "y=Y_train\n",
        "test_x=X_test\n",
        "test_y=Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPnqOfvj7oNE"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwkRAjD48EGt"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1,hidden_size2, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size1 = hidden_size1\n",
        "        self.hidden_size2 = hidden_size2\n",
        "        \n",
        "        self.i2h1 = nn.Linear(input_size + hidden_size2, hidden_size1)\n",
        "        self.h1h2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.h2o = nn.Linear(hidden_size2, output_size)\n",
        "        \n",
        "        #self.i2o = nn.Linear(input_size + hidden_size2, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat([input,hidden],1)\n",
        "        hidden1 = self.i2h1(combined)\n",
        "        hidden2 = self.h1h2(hidden1)\n",
        "        output = self.h2o(hidden2)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden2\n",
        "\n",
        "    def initHidden1(self):\n",
        "        return torch.zeros(1,self.hidden_size1)\n",
        "    \n",
        "    def initHidden2(self):\n",
        "        return torch.zeros(1, self.hidden_size2)\n",
        "    \n",
        "rnn = RNN(300, 50,10, 3)\n",
        "learning_rate=0.1\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn06vhqv8O_i"
      },
      "outputs": [],
      "source": [
        "epochs=2\n",
        "\n",
        "rnn =rnn.float()\n",
        "for i in range(epochs):\n",
        "    \n",
        "    for j in range(len(x)):\n",
        "        #print(\"j\",j)\n",
        "        hidden2 = rnn.initHidden2()\n",
        "        optimizer.zero_grad()\n",
        "        #pred=[]\n",
        "        #Hidden state - 20. Sending word by word vectors into RNN\n",
        "        for index in range(20):\n",
        "            temp=x.iloc[j,index]\n",
        "            temp=np.reshape(temp,(1,300))\n",
        "            temp_df=torch.tensor(temp)\n",
        "            output, hidden2 = rnn(temp_df.float(), hidden2.float())\n",
        "        #print(\"output\",output)\n",
        "        if(j==0):\n",
        "            pred=output\n",
        "        else:\n",
        "            pred=torch.cat([pred,output],0)\n",
        "        \n",
        "loss = criterion(pred, torch.tensor(np.array(y)-1))\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-pWCJe2JYoK"
      },
      "outputs": [],
      "source": [
        "for j in range(len(test_x)):\n",
        "    hidden2 = rnn.initHidden2()\n",
        "    optimizer.zero_grad()\n",
        "    #pred=[]\n",
        "    for index in range(20):\n",
        "        temp=test_x.iloc[j,index]\n",
        "        temp=np.reshape(temp,(1,300))\n",
        "        temp_df=torch.tensor(temp)\n",
        "        output, hidden2 = rnn(temp_df.float(), hidden2.float())\n",
        "    #pred.append(output)\n",
        "    if(j==0):\n",
        "        pred=output\n",
        "    else:\n",
        "        pred=torch.cat([pred,output],0)\n",
        "\n",
        "_,predicted = torch.max(pred.data,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwPmytFR7oNF",
        "outputId": "d67aa6fd-8731-4a2f-9de0-cd05ff80da38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy RNN 5(a): 36.525\n"
          ]
        }
      ],
      "source": [
        "correct=0\n",
        "#correct = (predicted == np.array(test_y)).sum()\n",
        "for i in range(len(predicted)):\n",
        "    if predicted[i]==list(test_y)[i]:\n",
        "        correct+=1\n",
        "print(\"Accuracy RNN 5(a):\",correct*100/len(test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61WciQo7oNG"
      },
      "source": [
        "Comparing accuracy of RNN and Feed Forward Neural Network, FFNN got better accuracy of 61% approx, whereas Rnn did not perform well.\n",
        "\n",
        "Can conclude that dataset is quite small in size and performs well on straight forward network. In my opinion with good enough epochs, more hyperparameter tunning and hit-n-trail approach RNN can work better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlOS6J-g7oNG"
      },
      "source": [
        "## GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vAqesaF7oNG"
      },
      "outputs": [],
      "source": [
        "# define the GRU architecture\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Number of hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # GRU\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "    # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "\n",
        "        # One time step\n",
        "        out, hn = self.gru(x, h0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "gru = GRUModel(300, 20, 1, 5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer= torch.optim.SGD(gru.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xX-z_5Y7oNG"
      },
      "outputs": [],
      "source": [
        "epochs=1\n",
        "\n",
        "gru =gru.float()\n",
        "for i in range(epochs):\n",
        "    \n",
        "    for j in range(len(x)):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred=[]\n",
        "        for index in range(20):\n",
        "            temp=x.iloc[j,index]\n",
        "            temp=np.reshape(temp,(1,300))\n",
        "            temp_df=torch.tensor(temp)\n",
        "            output = gru(temp_df.float())\n",
        "        pred.append(output)\n",
        "    #print(output.shape)\n",
        "    ten=pred[0]\n",
        "    for t in range(1,len(pred)):\n",
        "        torch.cat([ten,t],0)\n",
        "    \n",
        "    print(ten.shape())\n",
        "    loss = criterion(output, torch.tensor(y))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaVF7h3X7oNH"
      },
      "outputs": [],
      "source": [
        "for j in range(len(test_x)):\n",
        "    hidden2 = rnn.initHidden2()\n",
        "    optimizer.zero_grad()\n",
        "    #pred=[]\n",
        "    for index in range(20):\n",
        "        temp=test_x.iloc[j,index]\n",
        "        temp=np.reshape(temp,(1,300))\n",
        "        temp_df=torch.tensor(temp)\n",
        "        output, hidden2 = rnn(temp_df.float(), hidden2.float())\n",
        "    #pred.append(output)\n",
        "    if(j==0):\n",
        "        pred=output\n",
        "    else:\n",
        "        pred=torch.cat([pred,output],0)\n",
        "\n",
        "_,predicted = torch.max(pred.data,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC1pEGkC7oNH",
        "outputId": "90a71c36-982b-4a7d-dcbc-241d4d4e2ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy GRU 5(b): 40.69166666666667\n"
          ]
        }
      ],
      "source": [
        "correct=0\n",
        "#correct = (predicted == np.array(test_y)).sum()\n",
        "for i in range(len(predicted)):\n",
        "    if predicted[i]==list(test_y)[i]:\n",
        "        correct+=1\n",
        "print(\"Accuracy GRU 5(b):\",correct*100/len(test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty9chXrn7oNI"
      },
      "source": [
        "GRU performance is not good compare to FFNN on the basis of accuracy.\n",
        "\n",
        "Conclusion: Reason behind is could be that dataset is quite small in size and performs well on straight forward network. With good and sufficient epochs, more hyperparameter tunning and hit-n-trail approach GRU may work better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_muYbDA_7oNQ"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1wBdmwp7oNR"
      },
      "outputs": [],
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        #self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        # -> x needs to be: (batch_size, seq, input_size)\n",
        "        \n",
        "        # or:\n",
        "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden states (and cell states for LSTM)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device) \n",
        "        #c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        \n",
        "        # x: (n, 28, 28), h0: (2, n, 128)\n",
        "        \n",
        "        # Forward propagate RNN\n",
        "        out, _ = self.rnn(x, h0)  \n",
        "        # or:\n",
        "        #out, _ = self.lstm(x, (h0,c0))  \n",
        "        \n",
        "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        # out: (n, 28, 128)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        # out: (n, 128)\n",
        "         \n",
        "        out = self.fc(out)\n",
        "        # out: (n, 10)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEACxJJu7oNS"
      },
      "outputs": [],
      "source": [
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP2ZhJQQ7oNS"
      },
      "outputs": [],
      "source": [
        "epochs=1\n",
        "\n",
        "gru =gru.float()\n",
        "for i in range(epochs):\n",
        "    \n",
        "    for j in range(len(x)):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred=[]\n",
        "        for index in range(20):\n",
        "            temp=x.iloc[j,index]\n",
        "            temp=np.reshape(temp,(1,300))\n",
        "            temp_df=torch.tensor(temp)\n",
        "            output = gru(temp_df.float())\n",
        "        pred.append(output)\n",
        "    #print(output.shape)\n",
        "    ten=pred[0]\n",
        "    for t in range(1,len(pred)):\n",
        "        torch.cat([ten,t],0)\n",
        "    \n",
        "    print(ten.shape())\n",
        "    loss = criterion(output, torch.tensor(y))\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWibS5Dq7oNT"
      },
      "outputs": [],
      "source": [
        "for j in range(len(test_x)):\n",
        "    hidden2 = rnn.initHidden2()\n",
        "    optimizer.zero_grad()\n",
        "    #pred=[]\n",
        "    for index in range(20):\n",
        "        temp=test_x.iloc[j,index]\n",
        "        temp=np.reshape(temp,(1,300))\n",
        "        temp_df=torch.tensor(temp)\n",
        "        output, hidden2 = rnn(temp_df.float(), hidden2.float())\n",
        "    #pred.append(output)\n",
        "    if(j==0):\n",
        "        pred=output\n",
        "    else:\n",
        "        pred=torch.cat([pred,output],0)\n",
        "\n",
        "_,predicted = torch.max(pred.data,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx2Chblj7oNT",
        "outputId": "950dd322-2397-42ed-e03d-779233345306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy LSTM 5(c): 41.525\n"
          ]
        }
      ],
      "source": [
        "correct=0\n",
        "#correct = (predicted == np.array(test_y)).sum()\n",
        "for i in range(len(predicted)):\n",
        "    if predicted[i]==list(test_y)[i]:\n",
        "        correct+=1\n",
        "print(\"Accuracy LSTM 5(c):\",correct*100/len(test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78laqYcA7oNT"
      },
      "source": [
        "It was observed that the Feed Forward Neural Network performed better than the LSTM model. However, it is important to note that the dataset used in the experiment was relatively small and noisy, which may have affected it performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKT9wlI37oNT"
      },
      "source": [
        "LSTM and GRU models exhibit slightly better performance than Simple RNN models, but all three models have relatively lower accuracies compared to Feed Forward Neural Networks and SVMs in a simple model. It is important to note that truncating the sentences to 20 words may have resulted in the loss of critical information that could have contributed to sequential learning.\n",
        "\n",
        "It is worth exploring different ways to preprocess the data, such as increasing the maximum sequence length or padding the shorter sequences, to ensure that the models have access to the full context of the text. Additionally, trying out different hyperparameters or using pre-trained embeddings could potentially improve the performance of the recurrent models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.9 ('nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "0fb4ea86a3da87d762f65431a29491a17bfe8b2cb11b0da04a22d0c3d717383a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}